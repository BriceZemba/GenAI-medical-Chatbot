# Medical AI Chatbot (RAG System)

Ce projet est un chatbot m√©dical intelligent de bout en bout (End-to-End). Il utilise l'architecture **RAG (Retrieval-Augmented Generation)** pour fournir des r√©ponses pr√©cises et contextuelles bas√©es sur des documents m√©dicaux de confiance, √©vitant ainsi les hallucinations des mod√®les d'IA standards.

## Fonctionnalit√©s Cl√©s

* **R√©cup√©ration de Connaissance (Retrieval)** : Analyse des documents PDF m√©dicaux pour extraire des informations pertinentes.
* **Base de Donn√©es Vectorielle** : Utilisation de **Pinecone** pour un stockage et une recherche s√©mantique ultra-rapide des connaissances.
* **Intelligence Artificielle** : Int√©gration de **Google Gemini 1.5 Flash** pour une g√©n√©ration de r√©ponses naturelle et pr√©cise.
* **Interface Web Intuitive** : Une interface de chat fluide d√©velopp√©e avec Flask pour une interaction utilisateur simplifi√©e.
* **Prompt Engineering** : Syst√®me de prompt optimis√© pour garantir un comportement professionnel et s√©curis√© du chatbot.

## Architecture du Projet

Le syst√®me fonctionne selon un pipeline structur√© :

1. **Chargement & Split** : Les documents m√©dicaux sont d√©coup√©s en "chunks" g√©rables.
2. **Embeddings** : Transformation du texte en vecteurs math√©matiques.
3. **Stockage** : Indexation dans la base de donn√©es Pinecone.
4. **Inf√©rence** : Lorsqu'une question est pos√©e, le syst√®me r√©cup√®re les 3 segments les plus proches s√©mantiquement avant de g√©n√©rer la r√©ponse finale.

## üõ†Ô∏è Stack Technique

* **Backend** : Python, Flask.
* **LLM** : LangChain, Google Generative AI (Gemini).
* **Embeddings** : HuggingFace / LangChain Embeddings.
* **Vector Database** : Pinecone.
* **Parsing** : PyPDFLoader, RecursiveCharacterTextSplitter.

## Installation et Configuration

### 1. Cloner le projet

```bash
git clone https://github.com/votre-username/medical-chatbot-rag.git
cd medical-chatbot-rag

```

### 2. Configurer les variables d'environnement

Cr√©ez un fichier `.env` √† la racine :

```env
PINECONE_API_KEY=votre_cle_pinecone
GOOGLE_API_KEY=votre_cle_gemini

```

### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt

```

### 4. Lancer l'application

```bash
python app.py

```

Acc√©dez √† l'interface sur `http://127.0.0.1:5000`.

## Structure du Code

* `app.py` : Point d'entr√©e de l'application Flask et orchestration des cha√Ænes RAG.
* `src/helper.py` : Fonctions utilitaires pour le chargement des embeddings.
* `src/prompt.py` : D√©finition du `system_prompt` pour guider le comportement de l'IA.
* `templates/` : Interface utilisateur (HTML/JS).

---

## Rapport Technique

Un rapport technique approfondi est disponible pour ce projet. Il d√©taille :

* Le choix de la strat√©gie de d√©coupage du texte (Chunking).
* L'√©valuation de la pertinence des r√©sultats de recherche Pinecone.
* La gestion de la latence entre le serveur Flask et l'API Gemini.

**[T√©l√©charger le Rapport Technique (PDF)](./rapport_technique.pdf)**
## Licence

Ce projet est distribu√© sous la licence MIT.
